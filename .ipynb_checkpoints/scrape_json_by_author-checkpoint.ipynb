{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2c5612-d3d6-4a43-b964-f0f8a1d51949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this script reads json files and aggregates relative word frequencies by author\n",
    "\n",
    "#libraries we need\n",
    "import bz2\n",
    "import orjson\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "#create author_frequencies which holds word frequencies for each author\n",
    "author_frequencies = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "#load the target word list from a .txt file\n",
    "def load_word_list(word_list_file):\n",
    "    with open(word_list_file, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "    return set(words)\n",
    "\n",
    "#extract_word_frequencies gets us the word frequencies from a json file\n",
    "def extract_word_frequencies(file_name):\n",
    "    try:\n",
    "        #taking the zipped bs2 file as the input\n",
    "        with bz2.BZ2File(file_name, 'rb') as input_file:\n",
    "            #read, decode\n",
    "            input_file_content = input_file.read()\n",
    "            json_input = input_file_content.decode('utf-8')\n",
    "            #load it\n",
    "            data = orjson.loads(json_input)\n",
    "            #and define a dictionary\n",
    "            word_frequencies = defaultdict(int)\n",
    "\n",
    "            #extract pages and token frequencies\n",
    "            features = data.get('features', {})\n",
    "            if 'pages' in features and isinstance(features['pages'], list):\n",
    "                pages = features['pages']\n",
    "                body = [d['body'] for d in pages if 'body' in d]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid format for 'pages' field, expected a list.\")\n",
    "\n",
    "            #iterate through each page's body to accumulate word counts\n",
    "            for page_body in body:\n",
    "                if isinstance(page_body, dict):\n",
    "                    #token_pos_count holds what it says\n",
    "                    token_pos_count = page_body.get('tokenPosCount', {})\n",
    "                    #for word and tags_data in token_pos_count\n",
    "                    for word, tags_data in token_pos_count.items():\n",
    "                        #lower\n",
    "                        word = word.lower()\n",
    "                        #remove puncutation and whitespace\n",
    "                        word = re.sub(r'\\d+', '', word)\n",
    "                        word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "                        word = word.strip()\n",
    "\n",
    "                        if word and isinstance(tags_data, dict):\n",
    "                            for _, frequency in tags_data.items():\n",
    "                                if isinstance(frequency, int):\n",
    "                                    word_frequencies[word] += frequency\n",
    "\n",
    "            #calculate total word count\n",
    "            total_words = sum(word_frequencies.values())\n",
    "            # and relative frequencies\n",
    "            relative_frequencies = {word: (count / total_words) * 100 for word, count in word_frequencies.items()}\n",
    "            return relative_frequencies\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "#accumulate frequencies by author\n",
    "def accumulate_frequencies_by_author(relative_frequencies, author_name, target_words):\n",
    "    #for word and relative frequency in relative_frequencies\n",
    "    for word, relative_freq in relative_frequencies.items():\n",
    "        #if word in target_words\n",
    "        if word in target_words:\n",
    "            #append the word and relative frequency to author_frequencies\n",
    "            author_frequencies[author_name][word].append(relative_freq)\n",
    "\n",
    "#write_author_frequencies_to_csv does what it suggests\n",
    "def write_author_frequencies_to_csv(author_name):\n",
    "    #create a csv file named for the author\n",
    "    csv_file = f\"{author_name}.csv\"\n",
    "\n",
    "    #open it\n",
    "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        #write our column headers\n",
    "        writer.writerow([\"word_type\", \"median_relative_frequency\"])\n",
    "\n",
    "        #calculate median relative frequency for each word type\n",
    "        for word_type, freq_list in author_frequencies[author_name].items():\n",
    "            median_freq = np.median(freq_list)\n",
    "            writer.writerow([word_type, median_freq])\n",
    "\n",
    "    #clear author_frequencies we've accumulated to start the process over\n",
    "    author_frequencies[author_name].clear()\n",
    "\n",
    "#process json files from csv loads the jsons, accumulates the frequencies and writes the result\n",
    "def process_json_files_from_csv(csv_file, word_list_file):\n",
    "    \n",
    "    #create df which reads the author_jsons.csv\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    #target words pulls in the word list (mfws.txt)\n",
    "    target_words = load_word_list(word_list_file)\n",
    "\n",
    "    #clears the current author\n",
    "    current_author = None\n",
    "\n",
    "    #for row in df\n",
    "    for _, row in df.iterrows():\n",
    "        #take the author name and file_path\n",
    "        file_path = row['file_path']\n",
    "        author_name = row['author']\n",
    "\n",
    "        #if we've moved onto a new author, write out the data for the previous one\n",
    "        if current_author and author_name != current_author:\n",
    "            write_author_frequencies_to_csv(current_author)\n",
    "\n",
    "        #set current author equal to current file's author\n",
    "        current_author = author_name\n",
    "\n",
    "        #process the json file and accumulate relative frequencies\n",
    "        relative_frequencies = extract_word_frequencies(file_path)\n",
    "        if relative_frequencies:\n",
    "            accumulate_frequencies_by_author(relative_frequencies, author_name, target_words)\n",
    "\n",
    "    #write the last author's accumulated frequencies\n",
    "    if current_author:\n",
    "        write_author_frequencies_to_csv(current_author)\n",
    "\n",
    "#specify the CSV file and word list file\n",
    "csv_file = 'author_jsons.csv'\n",
    "word_list_file = 'mfws.txt'\n",
    "\n",
    "#run the main function\n",
    "process_json_files_from_csv(csv_file, word_list_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
