{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b3ef7d-1507-48a9-8975-48ae8cebaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in the libraries we want\n",
    "import bz2\n",
    "import orjson\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "#dictionary to store word frequencies for each author\n",
    "author_frequencies = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "#load the target word list from a .txt file\n",
    "def load_word_list(word_list_file):\n",
    "    with open(word_list_file, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "    return set(words)\n",
    "\n",
    "#load word replacement mappings from a CSV file\n",
    "def load_replacement_map(replacement_csv):\n",
    "    replacements = {}\n",
    "    with open(replacement_csv, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        rows = list(reader)\n",
    "\n",
    "        #check if the first row contains headers\n",
    "        if rows[0][0].lower() == 'id1' and rows[0][1].lower() == 'id2':\n",
    "            #skip the header row\n",
    "            rows = rows[1:]\n",
    "\n",
    "        #process the rows\n",
    "        for row in rows:\n",
    "            if len(row) >= 2: #make sure there's at least two columns\n",
    "                replacements[row[0]] = row[1]\n",
    "\n",
    "    return replacements\n",
    "\n",
    "#extract word frequencies from a single JSON file, applying replacements\n",
    "def extract_word_frequencies(file_name, replacements):\n",
    "    try:\n",
    "        #load the compressed json\n",
    "        with bz2.BZ2File(file_name, 'rb') as input_file:\n",
    "            #read and decode\n",
    "            input_file_content = input_file.read()\n",
    "            json_input = input_file_content.decode('utf-8')\n",
    "            data = orjson.loads(json_input)\n",
    "            word_frequencies = defaultdict(int)\n",
    "\n",
    "            #get 'features' and assign the result to features\n",
    "            features = data.get('features', {})\n",
    "            #if pages is in there and its a list\n",
    "            if 'pages' in features and isinstance(features['pages'], list):\n",
    "                #slice features\n",
    "                pages = features['pages']\n",
    "                #get everything in pages if body is in there\n",
    "                body = [d['body'] for d in pages if 'body' in d]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid format for 'pages' field, expected a list.\")\n",
    "\n",
    "            #iterate through every page's body to accumulate word counts\n",
    "            for page_body in body:\n",
    "                if isinstance(page_body, dict):\n",
    "                    #get token_pos_count, assign result as shown\n",
    "                    token_pos_count = page_body.get('tokenPosCount', {})\n",
    "                    #for word, tags_data in token_pos_count\n",
    "                    for word, tags_data in token_pos_count.items():\n",
    "                        #lowercase, replace numbers, blank space and punctuation\n",
    "                        word = word.lower()\n",
    "                        word = re.sub(r'\\d+', '', word)\n",
    "                        word = word.translate(str.maketrans('', '', string.punctuation))\n",
    "                        word = word.strip()\n",
    "\n",
    "                        #apply a replacement if the word is in the mapping\n",
    "                        word = replacements.get(word, word)\n",
    "\n",
    "                        #if tags_data is a dictionary, for every frequency and word, aggregate\n",
    "                        if word and isinstance(tags_data, dict):\n",
    "                            for _, frequency in tags_data.items():\n",
    "                                if isinstance(frequency, int):\n",
    "                                    word_frequencies[word] += frequency\n",
    "\n",
    "            #calculate total word count and compute the relative frequencies\n",
    "            total_words = sum(word_frequencies.values())\n",
    "            relative_frequencies = {word: (count / total_words) * 100 for word, count in word_frequencies.items()}\n",
    "            return relative_frequencies\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "#accumulate frequencies by author\n",
    "def accumulate_frequencies_by_author(relative_frequencies, author_name, target_words):\n",
    "    \"\"\"Store relative frequencies for target words for each author.\"\"\"\n",
    "    for word, relative_freq in relative_frequencies.items():\n",
    "        if word in target_words:\n",
    "            author_frequencies[author_name][word].append(relative_freq)\n",
    "\n",
    "#rrite aggregated median frequencies to CSV for each author\n",
    "def write_author_frequencies_to_csv(author_name):\n",
    "    csv_file = f\"{author_name}.csv\"\n",
    "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"word_type\", \"median_relative_frequency\"])\n",
    "\n",
    "        #compute the median relative frequency for each word type\n",
    "        for word_type, freq_list in author_frequencies[author_name].items():\n",
    "            median_freq = np.median(freq_list)\n",
    "            writer.writerow([word_type, median_freq])\n",
    "\n",
    "    #clear accumulated data for the author\n",
    "    author_frequencies[author_name].clear()\n",
    "\n",
    "#process json_files_from_csv accumulates frequencies by author and writes the result\n",
    "def process_json_files_from_csv(csv_file, word_list_file, replacement_csv):\n",
    "    #load word replacements and target words\n",
    "    replacements = load_replacement_map(replacement_csv)\n",
    "    target_words = load_word_list(word_list_file)\n",
    "\n",
    "    #read author csv and assign result to df\n",
    "    df = pd.read_csv(csv_file)\n",
    "    current_author = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        file_path = row['file_path']\n",
    "        author_name = row['author']\n",
    "\n",
    "        #write out data for the previous author if moving to a new one\n",
    "        if current_author and author_name != current_author:\n",
    "            write_author_frequencies_to_csv(current_author)\n",
    "\n",
    "        #set the current author to the current file's author\n",
    "        current_author = author_name\n",
    "\n",
    "        #process the JSON file and accumulate relative frequencies for the author\n",
    "        relative_frequencies = extract_word_frequencies(file_path, replacements)\n",
    "        if relative_frequencies:\n",
    "            accumulate_frequencies_by_author(relative_frequencies, author_name, target_words)\n",
    "\n",
    "    #write the last author's accumulated frequencies\n",
    "    if current_author:\n",
    "        write_author_frequencies_to_csv(current_author)\n",
    "\n",
    "#specify the CSV file, word list file, and replacement CSV file\n",
    "csv_file = 'author_jsons.csv'\n",
    "word_list_file = 'mfws.txt'\n",
    "replacement_csv = 'replacement_words.csv'\n",
    "\n",
    "#run the main processing function\n",
    "process_json_files_from_csv(csv_file, word_list_file, replacement_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
